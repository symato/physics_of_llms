'''
https://www.regular-expressions.info/unicode.html
https://stackoverflow.com/questions/38615740/regular-expression-to-accept-all-thai-characters-and-english-letters-in-python#answer-72440821
https://pypi.org/project/regex/
'''
import regex

def contains_cjk(token):
    for char in token:
        o = ord(char)
        if min_cjk <= o and o <= max_cjk:
            return True
    return False

def is_ascii(token):
    for char in token:
        if ord(char) > 255:
            return False
    return True

unwanted_langs = '''
\p{Arabic}
\p{Armenian}
\p{Bengali}
\p{Bopomofo}
\p{Braille}
\p{Buhid}
\p{Cherokee}
\p{Cyrillic}
\p{Devanagari}
\p{Ethiopic}
\p{Georgian}
\p{Greek}
\p{Gujarati}
\p{Gurmukhi}
\p{Hanunoo}
\p{Hebrew}
\p{Hiragana}
\p{Inherited}
\p{Kannada}
\p{Katakana}
\p{Khmer}
\p{Lao}
\p{Limbu}
\p{Malayalam}
\p{Mongolian}
\p{Myanmar}
\p{Ogham}
\p{Oriya}
\p{Runic}
\p{Sinhala}
\p{Syriac}
\p{Tagalog}
\p{Tagbanwa}
\p{TaiLe}
\p{Tamil}
\p{Telugu}
\p{Thaana}
\p{Thai}
\p{Tibetan}
\p{Yi}
'''.strip().split()

unwanted_langs = "".join(unwanted_langs)
unwanted_langs_re = regex.compile(f'[{unwanted_langs}]+')


# https://emoji-python.readthedocs.io/en/stable/
from emoji import emoji_count # python -m pip install emoji --upgrade

def contains_emoji(token):
    return emoji_count(token) > 0

def contains_unwanted(token):
    if contains_cjk(token):
        return True

    m = regex.findall(unwanted_langs_re, token)
    for x in m:
        for c in x:
            if ord(c) > 255: # not ascii
                return True
    return False


vi_chars = {'á»›', 'á»', 'á»¥', 'áº«', 'á»•', 'áº­', 'áºµ', 'Ã¢', 'áº·', 'á»…', 'á»', 'áº©', 'á»¹', 'áº½', 'á»§', 'áº¡', 'áº¥', 'Æ°', 'áº£', 'á»‰', 'á»—', 'á»“', 'á»©', 'Ä‘', 
'á»±', 'Ã¨', 'Ã½', 'áº¿', 'á»µ', 'Å©', 'áº¯', 'áº»', 'á»ƒ', 'á»£', 'á»‡', 'áº³', 'á»™', 'Ã ', 'Ãµ', 'Ä©', 'áº±', 'áº¹', 'á»³', 'Ã©', 'á»­', 'á»‹', 'á»Ÿ', 'á»¡', 'Ãª', 
'áº§', 'Ã²', 'á»', 'á»‘', 'á»·', 'Äƒ', 'Ã¬', 'á»¯', 'Æ¡', 'Ã£', 'á»', 'á»«', 'Ã¹', 'Ãº', 'Ã¡', 'Ã´', 'Ã­', 'Ã³',
'a', 'b', 'c', 'd', 'e', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', ' ',
'"', "'", ".", ",", ";" }

def canbe_vietnamese(token):
    for c in token.lower():
        if c not in vi_chars:
            return False
    return True

'''
The 4E00â€”9FFF range covers CJK Unified Ideographs (CJK=Chinese, Japanese and Korean). 
There are a number of lower ranges that relate, to some degree, to CJK:

31C0â€”31EF CJK Strokes
31F0â€”31FF Katakana Phonetic Extensions
3200â€”32FF Enclosed CJK Letters and Months
3300â€”33FF CJK Compatibility
3400â€”4DBF CJK Unified Ideographs Extension A
4DC0â€”4DFF Yijing Hexagram Symbols
4E00â€”9FFF CJK Unified Ideographs 
'''

min_cjk = 11935
# min_cjk = ord('\u31c0')

max_cjk = 64055
# max_cjk = ord('\u9fff')

if __name__ ==  "__main__":

    unwanted = """
à¸—à¸£à¸¹à¸§à¸´à¸Šà¸±à¹ˆà¸™à¸ªà¹Œasdf, áº§ds tiáº¿n lÃªn
ê²Œì‹œíŒ
í™œ
â½—
ï¤¦
ï¥ 
ï¥±
âºŸ
ï¦ƒ
ï§©
ï¨‚
ï¨Š
ï¨·
""".strip().split("\n")

    for x in unwanted:
        if not contains_unwanted(x):
         print(x)
         print(min_cjk, max_cjk)
         for c in x:
            print(ord(c), c)


    emoji_samples = """
ğŸˆ¯
ğŸˆ²
ğŸˆ¹
ğŸŒ‡
ğŸŒ“
ğŸ˜
ğŸ‘
ğŸ¿
ğŸ
ğŸ’
ğŸ©
ğŸ¯
ğŸ€
ğŸ‘
ğŸ’¹
ğŸ’º
ğŸ“Ÿ
ğŸ“ª
ğŸ“¼
ğŸ”€ğŸ”‚
ğŸ”ƒ
ğŸ”‡
ğŸ”“
ğŸ”¢
ğŸ”¤ğŸ”©
ğŸ•–
ğŸ•š
ğŸ•œ
ğŸ•
ğŸ•
ğŸ• ğŸ•¢
ğŸŒ,
 ğŸ˜‚, ğŸ˜ƒ,
 ğŸ˜‚
    """.strip().split("\n")
    
    for x in emoji_samples:
        if not contains_emoji(x):
            print(x, emoji_count(x))


    vi_samples = """
    hÃª hÃª
    an
    " VIá»†T

    """.strip().split("\n")

    for x in vi_samples:
        if not canbe_vietnamese(x):
            print(x)
